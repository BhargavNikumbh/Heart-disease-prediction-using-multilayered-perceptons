{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the datasets\n",
    "def read_dataset():\n",
    "    df=pd.read_csv('heart.csv')\n",
    "    X=df.iloc[: , :-1].values\n",
    "    y=df.iloc[: ,-1].values\n",
    "    \n",
    "    #encode dependent variable\n",
    "    encoder=LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y_=encoder.transform(y)\n",
    "    Y=one_hot_encoder(y_)\n",
    "    print(X.shape)\n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the encoder function\n",
    "def one_hot_encoder(labels):\n",
    "    n_labels=len(labels)\n",
    "    n_unique_labels=len(np.unique(labels))\n",
    "    one_hot_encoder=np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encoder[np.arange(n_labels),labels]=1\n",
    "    return one_hot_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n"
     ]
    }
   ],
   "source": [
    "X,Y=read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle dataset\n",
    "X,Y=shuffle(X,Y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test set\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=0.2,random_state=421)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43.  1.  0. ...  1.  0.  3.]\n",
      " [51.  0.  2. ...  2.  0.  2.]\n",
      " [55.  1.  0. ...  1.  1.  3.]\n",
      " ...\n",
      " [58.  1.  1. ...  1.  4.  3.]\n",
      " [61.  1.  0. ...  1.  1.  2.]\n",
      " [60.  0.  2. ...  2.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "print(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13)\n",
      "(242, 2)\n",
      "(61, 13)\n"
     ]
    }
   ],
   "source": [
    "#check train and test set\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim 13\n"
     ]
    }
   ],
   "source": [
    "#define important paarmeters & variables to work with tensors\n",
    "learning_rate=0.2\n",
    "training_epoch=1000\n",
    "cost_history=np.empty(shape=[1],dtype=float)\n",
    "n_dim=X.shape[1]\n",
    "print('n_dim',n_dim)\n",
    "n_class=2 #0 and 1\n",
    "model_path=\"C://Desktop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#define the number of hidden layers & number of neurons for each layer\n",
    "n_hidden_1=60\n",
    "n_hidden_2=60\n",
    "n_hidden_3=60\n",
    "\n",
    "x=tf.placeholder(shape=[None,n_dim],dtype=tf.float32)\n",
    "W=tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b=tf.Variable(tf.zeros([n_class]))\n",
    "y_=tf.placeholder(shape=[None,n_class],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    #hidden layers with RELU activators\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1=tf.nn.sigmoid(layer_1)\n",
    "    #hidden layers with Sigmoid activation\n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2=tf.nn.sigmoid(layer_2)\n",
    "    #hidden layer with relu activation\n",
    "    layer_3=tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3=tf.nn.relu(layer_3)\n",
    "  \n",
    "    #output layer with algorithm\n",
    "    out_layer=tf.matmul(layer_3,weights['out'])+biases['out']\n",
    "    return out_layer\n",
    "\n",
    "weights={\n",
    "    'h1':tf.Variable(tf.truncated_normal([n_dim,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden_3,n_class]))\n",
    "}\n",
    "\n",
    "biases={\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_class])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize all the values\n",
    "init=tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()\n",
    "#call your defined model\n",
    "y=multilayer_perceptron(x,weights,biases)\n",
    "#loss function and optimizer\n",
    "cost_function=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y,labels=y_))\n",
    "training_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "sess=tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 - cost= 0.6278403 _mse= 1.7081375753208765 train Accuracy= 0.61157024\n",
      "0.0\n",
      "epoch= 1 - cost= 0.6161946 _mse= 1.6331850643747488 train Accuracy= 0.6487603\n",
      "0.0\n",
      "epoch= 2 - cost= 0.6172029 _mse= 1.6813939454539242 train Accuracy= 0.6487603\n",
      "0.0\n",
      "epoch= 3 - cost= 0.6145158 _mse= 1.722660936977168 train Accuracy= 0.6528926\n",
      "0.0\n",
      "epoch= 4 - cost= 0.62203634 _mse= 1.7202403395384478 train Accuracy= 0.6487603\n",
      "0.0\n",
      "epoch= 5 - cost= 0.6112172 _mse= 1.852972005211604 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 6 - cost= 0.6149955 _mse= 1.6706154921001384 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 7 - cost= 0.6178797 _mse= 1.706690763477829 train Accuracy= 0.6487603\n",
      "0.0\n",
      "epoch= 8 - cost= 0.6118015 _mse= 1.7654399884162901 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 9 - cost= 0.63313097 _mse= 1.6652786686781857 train Accuracy= 0.59917355\n",
      "0.0\n",
      "epoch= 10 - cost= 0.6341911 _mse= 1.7774534562488733 train Accuracy= 0.607438\n",
      "0.0\n",
      "epoch= 11 - cost= 0.6273458 _mse= 1.7029328420473144 train Accuracy= 0.607438\n",
      "0.0\n",
      "epoch= 12 - cost= 0.6188726 _mse= 1.6756910529184161 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 13 - cost= 0.6233858 _mse= 1.5344072870367567 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 14 - cost= 0.63872576 _mse= 1.5849929474961502 train Accuracy= 0.6528926\n",
      "0.0\n",
      "epoch= 15 - cost= 0.6206152 _mse= 1.5946040871495484 train Accuracy= 0.6487603\n",
      "0.0\n",
      "epoch= 16 - cost= 0.6229423 _mse= 1.728498532900901 train Accuracy= 0.6446281\n",
      "0.0\n",
      "epoch= 17 - cost= 0.630307 _mse= 1.4333762331099598 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 18 - cost= 0.6211587 _mse= 1.6352285805690632 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 19 - cost= 0.6259385 _mse= 1.6159404694627892 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 20 - cost= 0.62519073 _mse= 1.6443532321191994 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 21 - cost= 0.6233466 _mse= 1.5727390111846744 train Accuracy= 0.6694215\n",
      "0.0\n",
      "epoch= 22 - cost= 0.6274097 _mse= 1.5524469741191762 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 23 - cost= 0.6226347 _mse= 1.6197787140902746 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 24 - cost= 0.61982703 _mse= 1.5938880865876972 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 25 - cost= 0.6197925 _mse= 1.541783229402517 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 26 - cost= 0.62188214 _mse= 1.6651864404249028 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 27 - cost= 0.6187249 _mse= 1.6327466500890981 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 28 - cost= 0.6232562 _mse= 1.52322044180688 train Accuracy= 0.6735537\n",
      "0.0\n",
      "epoch= 29 - cost= 0.6388081 _mse= 1.3753458776088725 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 30 - cost= 0.63410085 _mse= 1.4681252030260774 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 31 - cost= 0.63201016 _mse= 1.385800401683805 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 32 - cost= 0.63364315 _mse= 1.3597223640525011 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 33 - cost= 0.6297001 _mse= 1.3474988524270164 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 34 - cost= 0.62425345 _mse= 1.3621543907557403 train Accuracy= 0.6735537\n",
      "0.0\n",
      "epoch= 35 - cost= 0.6381631 _mse= 1.2740429011799919 train Accuracy= 0.6487603\n",
      "0.0\n",
      "epoch= 36 - cost= 0.6319069 _mse= 1.3792801170462474 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 37 - cost= 0.62612414 _mse= 1.3149545263604332 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 38 - cost= 0.6261693 _mse= 1.303058878453881 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 39 - cost= 0.6232663 _mse= 1.3612618952766873 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 40 - cost= 0.6315698 _mse= 1.316970822478928 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 41 - cost= 0.6347442 _mse= 1.2747498144447071 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 42 - cost= 0.6249547 _mse= 1.2947968882879484 train Accuracy= 0.677686\n",
      "0.0\n",
      "epoch= 43 - cost= 0.6215083 _mse= 1.3949298471580864 train Accuracy= 0.677686\n",
      "0.0\n",
      "epoch= 44 - cost= 0.6266987 _mse= 1.2924834908552156 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 45 - cost= 0.6248792 _mse= 1.3787686146661637 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 46 - cost= 0.6242371 _mse= 1.3470348209356644 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 47 - cost= 0.624001 _mse= 1.3750057486007994 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 48 - cost= 0.6237479 _mse= 1.3588085255304443 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 49 - cost= 0.62356424 _mse= 1.384194562370345 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 50 - cost= 0.62338454 _mse= 1.3716571543736626 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 51 - cost= 0.62312543 _mse= 1.3949689398132246 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 52 - cost= 0.62263197 _mse= 1.3907676286548392 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 53 - cost= 0.6223328 _mse= 1.4149848476294404 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 54 - cost= 0.62209725 _mse= 1.4195737650156164 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 55 - cost= 0.6218865 _mse= 1.4359358764673338 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 56 - cost= 0.6217192 _mse= 1.4391708084132429 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 57 - cost= 0.6215715 _mse= 1.453071977493724 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 58 - cost= 0.621452 _mse= 1.4565327808077084 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 59 - cost= 0.62135756 _mse= 1.4670182459819012 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 60 - cost= 0.62127644 _mse= 1.4682902371641797 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 61 - cost= 0.62121487 _mse= 1.4766984891858508 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 62 - cost= 0.62118775 _mse= 1.4789198646120807 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 63 - cost= 0.6211658 _mse= 1.4854985799917075 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 64 - cost= 0.6211467 _mse= 1.4889959839625673 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 65 - cost= 0.62113035 _mse= 1.4953487451523768 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 66 - cost= 0.6211168 _mse= 1.4979784492510138 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 67 - cost= 0.6211026 _mse= 1.501581896986622 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 68 - cost= 0.621092 _mse= 1.505923278665779 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 69 - cost= 0.62107944 _mse= 1.5085069050604436 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 70 - cost= 0.6210472 _mse= 1.514436814686746 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 71 - cost= 0.6209991 _mse= 1.5178638357223226 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 72 - cost= 0.620912 _mse= 1.5225812771012308 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 73 - cost= 0.62083775 _mse= 1.5278200222185405 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 74 - cost= 0.6208275 _mse= 1.5320951638529772 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 75 - cost= 0.62081885 _mse= 1.5352918402445714 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 76 - cost= 0.6208108 _mse= 1.538857307798318 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 77 - cost= 0.6208057 _mse= 1.5388370895221612 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 78 - cost= 0.6207987 _mse= 1.5410926586408582 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 79 - cost= 0.62079287 _mse= 1.5437222970176294 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 80 - cost= 0.6207867 _mse= 1.5460493076818003 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 81 - cost= 0.6207811 _mse= 1.5483560142574215 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 82 - cost= 0.62077516 _mse= 1.5505530637141178 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 83 - cost= 0.6207698 _mse= 1.5527076847141204 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 84 - cost= 0.62076384 _mse= 1.5548211371274012 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 85 - cost= 0.6207581 _mse= 1.556895483193745 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 86 - cost= 0.62075263 _mse= 1.558943853597541 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 87 - cost= 0.6207471 _mse= 1.5608999631886205 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 88 - cost= 0.6207416 _mse= 1.5631703911608552 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 89 - cost= 0.6207359 _mse= 1.5651014821904552 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 90 - cost= 0.6207306 _mse= 1.5673784590881563 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 91 - cost= 0.6207253 _mse= 1.5692810639356252 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 92 - cost= 0.6207195 _mse= 1.5714833971964912 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 93 - cost= 0.62071455 _mse= 1.5736490043213553 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 94 - cost= 0.620709 _mse= 1.575844266730123 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 95 - cost= 0.6207034 _mse= 1.5780335441007196 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 96 - cost= 0.6206983 _mse= 1.5802189342109074 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 97 - cost= 0.62069285 _mse= 1.5823891903039728 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 98 - cost= 0.62068754 _mse= 1.5845564152357916 train Accuracy= 0.6652893\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 99 - cost= 0.62068284 _mse= 1.5867188717388616 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 100 - cost= 0.62072 _mse= 1.5778575901782619 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 101 - cost= 0.620706 _mse= 1.5815911228486457 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 102 - cost= 0.6206939 _mse= 1.5855327499842893 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 103 - cost= 0.62068254 _mse= 1.5892281511957156 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 104 - cost= 0.6206706 _mse= 1.5927745397725397 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 105 - cost= 0.6206593 _mse= 1.5958162795269064 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 106 - cost= 0.6206488 _mse= 1.598631658154303 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 107 - cost= 0.6206417 _mse= 1.601250661655598 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 108 - cost= 0.6206413 _mse= 1.6033093257288682 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 109 - cost= 0.62067664 _mse= 1.5940755281452945 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 110 - cost= 0.62066287 _mse= 1.5978221161045898 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 111 - cost= 0.6206506 _mse= 1.601748798406335 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 112 - cost= 0.6206385 _mse= 1.6054129857323272 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 113 - cost= 0.6206263 _mse= 1.6088394921416405 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 114 - cost= 0.62061393 _mse= 1.611846783803007 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 115 - cost= 0.62060446 _mse= 1.6146967935847454 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 116 - cost= 0.6205988 _mse= 1.6171582781926965 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 117 - cost= 0.6206383 _mse= 1.6065129583212994 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 118 - cost= 0.62063193 _mse= 1.5839907071676396 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 119 - cost= 0.62064344 _mse= 1.606900939101297 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 120 - cost= 0.62060326 _mse= 1.6240023323997625 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 121 - cost= 0.62058705 _mse= 1.622615722170371 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 122 - cost= 0.620575 _mse= 1.6262759291623905 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 123 - cost= 0.6205715 _mse= 1.6039239338933697 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 124 - cost= 0.6205965 _mse= 1.6240222279983323 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 125 - cost= 0.6206066 _mse= 1.6251065330761965 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 126 - cost= 0.6205836 _mse= 1.6160082965818474 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 127 - cost= 0.6205709 _mse= 1.6202440737675727 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 128 - cost= 0.62058026 _mse= 1.5923139673689826 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 129 - cost= 0.6206135 _mse= 1.6249810237257223 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 130 - cost= 0.620546 _mse= 1.64622147622442 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 131 - cost= 0.62053084 _mse= 1.6432991114141307 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 132 - cost= 0.62054485 _mse= 1.646869865842292 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 133 - cost= 0.6205725 _mse= 1.6115421095243374 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 134 - cost= 0.6205792 _mse= 1.6333860171004733 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 135 - cost= 0.6205461 _mse= 1.6467339527161176 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 136 - cost= 0.6205245 _mse= 1.6384589793185518 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 137 - cost= 0.6205099 _mse= 1.640913971608827 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 138 - cost= 0.620498 _mse= 1.6392946881980381 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 139 - cost= 0.6204888 _mse= 1.6446970129534233 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 140 - cost= 0.62050825 _mse= 1.6360852087893467 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 141 - cost= 0.6205476 _mse= 1.6415284647240316 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 142 - cost= 0.6206438 _mse= 1.5858216412187742 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 143 - cost= 0.6207579 _mse= 1.6397939874219059 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 144 - cost= 0.6205364 _mse= 1.684624459100295 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 145 - cost= 0.62048686 _mse= 1.6714005576398647 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 146 - cost= 0.6204702 _mse= 1.6794392203206503 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 147 - cost= 0.6204611 _mse= 1.680686620463116 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 148 - cost= 0.62050307 _mse= 1.6715335272809086 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 149 - cost= 0.6204898 _mse= 1.675316105805089 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 150 - cost= 0.6204764 _mse= 1.6792857036280793 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 151 - cost= 0.6204619 _mse= 1.6828328516986317 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 152 - cost= 0.6204469 _mse= 1.685957187467576 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 153 - cost= 0.62043446 _mse= 1.6890667346223962 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 154 - cost= 0.6204538 _mse= 1.6921254825121355 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 155 - cost= 0.62047595 _mse= 1.6809206284784508 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 156 - cost= 0.62046236 _mse= 1.6851502504073597 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 157 - cost= 0.6204492 _mse= 1.6891292818503247 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 158 - cost= 0.6204351 _mse= 1.6929807858744954 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 159 - cost= 0.6204208 _mse= 1.6973703222952787 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 160 - cost= 0.6204077 _mse= 1.7034188518389226 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 161 - cost= 0.6204197 _mse= 1.7075146558136471 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 162 - cost= 0.62044644 _mse= 1.6960308429296658 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 163 - cost= 0.620433 _mse= 1.7002140019487457 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 164 - cost= 0.62041974 _mse= 1.7041088505619937 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 165 - cost= 0.62040466 _mse= 1.7078300513633213 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 166 - cost= 0.62038946 _mse= 1.7109927588053293 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 167 - cost= 0.6204132 _mse= 1.667384400767886 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 168 - cost= 0.620486 _mse= 1.7046903119385792 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 169 - cost= 0.62042755 _mse= 1.7176575950443904 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 170 - cost= 0.62040615 _mse= 1.7136697212202479 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 171 - cost= 0.62039036 _mse= 1.7210565155930433 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 172 - cost= 0.6203731 _mse= 1.722922300277301 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 173 - cost= 0.6203572 _mse= 1.7272810695892755 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 174 - cost= 0.6203611 _mse= 1.730912252565772 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 175 - cost= 0.6203949 _mse= 1.7207301058144522 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 176 - cost= 0.6203812 _mse= 1.7250278790150348 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 177 - cost= 0.6203667 _mse= 1.729337089522678 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 178 - cost= 0.6203509 _mse= 1.7331202656748501 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 179 - cost= 0.62033474 _mse= 1.7365484775027127 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 180 - cost= 0.62032914 _mse= 1.7403855765133343 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 181 - cost= 0.62037617 _mse= 1.7338730777839706 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 182 - cost= 0.6203556 _mse= 1.7394049068626267 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 183 - cost= 0.6203392 _mse= 1.742636982047227 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 184 - cost= 0.6203214 _mse= 1.7469485873924506 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 185 - cost= 0.62030447 _mse= 1.7507120504578058 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 186 - cost= 0.6203408 _mse= 1.7545787830442054 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 187 - cost= 0.62035686 _mse= 1.7422914855561518 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 188 - cost= 0.6203373 _mse= 1.748032719517217 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 189 - cost= 0.6203217 _mse= 1.7516519032672488 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 190 - cost= 0.6203044 _mse= 1.7562884102748892 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 191 - cost= 0.6202864 _mse= 1.760111903546051 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 192 - cost= 0.6203007 _mse= 1.7643997024934954 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 193 - cost= 0.620331 _mse= 1.7524620426543567 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 194 - cost= 0.62032163 _mse= 1.7323217394300898 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 195 - cost= 0.6203215 _mse= 1.7551839829535738 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 196 - cost= 0.6202792 _mse= 1.775006383459732 train Accuracy= 0.6652893\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 197 - cost= 0.6202576 _mse= 1.7761925456100722 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 198 - cost= 0.620299 _mse= 1.7835228749259786 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 199 - cost= 0.6203103 _mse= 1.7720036296212849 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 200 - cost= 0.6202902 _mse= 1.777869277187603 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 201 - cost= 0.6202729 _mse= 1.7828424405709762 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 202 - cost= 0.6202543 _mse= 1.7892646419054525 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 203 - cost= 0.6202346 _mse= 1.795000924291047 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 204 - cost= 0.6202651 _mse= 1.8011276653270853 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 205 - cost= 0.6202864 _mse= 1.790710836867296 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 206 - cost= 0.6202654 _mse= 1.7963709645121342 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 207 - cost= 0.6202448 _mse= 1.7998115311083647 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 208 - cost= 0.62022626 _mse= 1.805943258103617 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 209 - cost= 0.6202061 _mse= 1.8122781536787853 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 210 - cost= 0.62025714 _mse= 1.8183134471816904 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 211 - cost= 0.6202676 _mse= 1.806616805382117 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 212 - cost= 0.62024444 _mse= 1.8125736780390769 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 213 - cost= 0.62022376 _mse= 1.815970847241114 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 214 - cost= 0.62020004 _mse= 1.820733757193571 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 215 - cost= 0.62018037 _mse= 1.8285866273314784 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 216 - cost= 0.6202345 _mse= 1.8214987187304796 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 217 - cost= 0.62021434 _mse= 1.8268534809298256 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 218 - cost= 0.62018865 _mse= 1.8302862397930646 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 219 - cost= 0.62016124 _mse= 1.835526094207855 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 220 - cost= 0.6202045 _mse= 1.8416046779027688 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 221 - cost= 0.6202122 _mse= 1.8301713057719065 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 222 - cost= 0.6201848 _mse= 1.8361410513737912 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 223 - cost= 0.6201463 _mse= 1.8395795968648314 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 224 - cost= 0.6200712 _mse= 1.8445801052521147 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 225 - cost= 0.6198196 _mse= 1.8493384118015554 train Accuracy= 0.6694215\n",
      "0.0\n",
      "epoch= 226 - cost= 0.61883 _mse= 1.8397237690167791 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 227 - cost= 0.62035495 _mse= 1.8086798833400686 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 228 - cost= 0.62027925 _mse= 1.834767839123809 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 229 - cost= 0.62016106 _mse= 1.8714948667421298 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 230 - cost= 0.6201851 _mse= 1.8676277221890316 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 231 - cost= 0.62020856 _mse= 1.8548605643246232 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 232 - cost= 0.6201918 _mse= 1.8587255002523961 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 233 - cost= 0.6201754 _mse= 1.8639789407930187 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 234 - cost= 0.62015575 _mse= 1.868453813622037 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 235 - cost= 0.6201301 _mse= 1.8727901087459926 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 236 - cost= 0.62014437 _mse= 1.8797401985678863 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 237 - cost= 0.6201751 _mse= 1.869330194647706 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 238 - cost= 0.6201579 _mse= 1.8753258498135699 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 239 - cost= 0.62013465 _mse= 1.8789659885108834 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 240 - cost= 0.6201058 _mse= 1.8842728717546537 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 241 - cost= 0.6201593 _mse= 1.8894544400916384 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 242 - cost= 0.62016356 _mse= 1.8765349057936356 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 243 - cost= 0.6201473 _mse= 1.882949520225166 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 244 - cost= 0.6201256 _mse= 1.8866775097534652 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 245 - cost= 0.6200995 _mse= 1.891893933168991 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 246 - cost= 0.62010884 _mse= 1.896946076714418 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 247 - cost= 0.6201396 _mse= 1.8881419655388223 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 248 - cost= 0.6201209 _mse= 1.8931140588162176 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 249 - cost= 0.62009627 _mse= 1.897565517386977 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 250 - cost= 0.6200648 _mse= 1.9022940658425767 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 251 - cost= 0.6201531 _mse= 1.9076654054535693 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 252 - cost= 0.62015927 _mse= 1.888913383423155 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 253 - cost= 0.62013185 _mse= 1.9033018309343193 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 254 - cost= 0.62011635 _mse= 1.9101668622939283 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 255 - cost= 0.62008595 _mse= 1.9073080902823996 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 256 - cost= 0.62005496 _mse= 1.9159122503648163 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 257 - cost= 0.620102 _mse= 1.921448017857169 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 258 - cost= 0.6201217 _mse= 1.9043344331131586 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 259 - cost= 0.62010556 _mse= 1.9127359862172872 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 260 - cost= 0.6200878 _mse= 1.9171044850885912 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 261 - cost= 0.62006474 _mse= 1.9231626268520468 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 262 - cost= 0.6200361 _mse= 1.928555609111886 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 263 - cost= 0.6200801 _mse= 1.937181930637645 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 264 - cost= 0.6200971 _mse= 1.9192784392077256 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 265 - cost= 0.62008214 _mse= 1.9253481242192045 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 266 - cost= 0.62006533 _mse= 1.9305249282184067 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 267 - cost= 0.62004733 _mse= 1.946140211148957 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 268 - cost= 0.62001544 _mse= 1.9509034323819348 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 269 - cost= 0.62006927 _mse= 1.95687833388605 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 270 - cost= 0.6200873 _mse= 1.937103307377891 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 271 - cost= 0.62007207 _mse= 1.9454298174311278 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 272 - cost= 0.62006384 _mse= 1.9494430486272891 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 273 - cost= 0.6200571 _mse= 1.9549487450825525 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 274 - cost= 0.620051 _mse= 1.9592439680976421 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 275 - cost= 0.6200449 _mse= 1.9634959027993761 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 276 - cost= 0.62003946 _mse= 1.9674619315564152 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 277 - cost= 0.62003386 _mse= 1.9713032239574817 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 278 - cost= 0.62002826 _mse= 1.9750190048343632 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 279 - cost= 0.6200228 _mse= 1.9786370647468638 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 280 - cost= 0.6200178 _mse= 1.9821679398451366 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 281 - cost= 0.620015 _mse= 1.98313427863998 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 282 - cost= 0.62001115 _mse= 1.986525237276694 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 283 - cost= 0.62000746 _mse= 1.9875956037103686 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 284 - cost= 0.62000495 _mse= 1.9885316192095495 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 285 - cost= 0.6200016 _mse= 1.9920769386869126 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 286 - cost= 0.61999816 _mse= 1.9932514803031482 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 287 - cost= 0.6199952 _mse= 1.99402911957606 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 288 - cost= 0.61999124 _mse= 2.0013781779534328 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 289 - cost= 0.61998785 _mse= 2.005900278750767 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 290 - cost= 0.6199855 _mse= 2.0075898738459035 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 291 - cost= 0.6199827 _mse= 2.0126251393143675 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 292 - cost= 0.6199791 _mse= 2.014418482359576 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 293 - cost= 0.6199763 _mse= 2.0162219245110884 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 294 - cost= 0.61997324 _mse= 2.018222523758824 train Accuracy= 0.6652893\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 295 - cost= 0.61997014 _mse= 2.019846607737001 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 296 - cost= 0.61996704 _mse= 2.0223450181424245 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 297 - cost= 0.61996454 _mse= 2.024383646395071 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 298 - cost= 0.61996174 _mse= 2.0291816313023787 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 299 - cost= 0.6199585 _mse= 2.0315285066849667 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 300 - cost= 0.6199554 _mse= 2.033376677183649 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 301 - cost= 0.6199543 _mse= 2.0392672268770964 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 302 - cost= 0.6199506 _mse= 2.039608351052721 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 303 - cost= 0.6199477 _mse= 2.04373435779161 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 304 - cost= 0.6199447 _mse= 2.0458749300647066 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 305 - cost= 0.61994183 _mse= 2.0484853688607854 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 306 - cost= 0.6199388 _mse= 2.0503144211176765 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 307 - cost= 0.61993575 _mse= 2.053109778533467 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 308 - cost= 0.61993265 _mse= 2.055354636947796 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 309 - cost= 0.6199304 _mse= 2.0572519398688 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 310 - cost= 0.6199277 _mse= 2.063001231136084 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 311 - cost= 0.61992407 _mse= 2.0650457415035772 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 312 - cost= 0.61991996 _mse= 2.0666813367717918 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 313 - cost= 0.6200317 _mse= 1.947760010681818 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 314 - cost= 0.6215771 _mse= 2.0691146037944117 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 315 - cost= 0.62253493 _mse= 2.3114804468423564 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 316 - cost= 0.620386 _mse= 2.0771981191501827 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 317 - cost= 0.62004554 _mse= 2.165523124979456 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 318 - cost= 0.61999416 _mse= 2.137495060286055 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 319 - cost= 0.61997706 _mse= 2.156429490004434 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 320 - cost= 0.61994684 _mse= 2.1532202061440158 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 321 - cost= 0.61994255 _mse= 2.1575969815471856 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 322 - cost= 0.6199356 _mse= 2.160277971054382 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 323 - cost= 0.6199197 _mse= 2.1605948544201574 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 324 - cost= 0.6199193 _mse= 2.164289368322653 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 325 - cost= 0.6199117 _mse= 2.163752551753825 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 326 - cost= 0.6199055 _mse= 2.167176347723456 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 327 - cost= 0.6199046 _mse= 2.166236310555754 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 328 - cost= 0.61989474 _mse= 2.169434521689318 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 329 - cost= 0.6198917 _mse= 2.170752298520397 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 330 - cost= 0.61989325 _mse= 2.1708006446758494 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 331 - cost= 0.6198855 _mse= 2.173446693936866 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 332 - cost= 0.619882 _mse= 2.174747858274657 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 333 - cost= 0.6198792 _mse= 2.1770770590820905 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 334 - cost= 0.61987615 _mse= 2.1791450694385923 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 335 - cost= 0.619873 _mse= 2.18134902601832 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 336 - cost= 0.61987036 _mse= 2.1835117955839602 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 337 - cost= 0.6198671 _mse= 2.185689105706192 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 338 - cost= 0.6198643 _mse= 2.1878613437571266 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 339 - cost= 0.6198613 _mse= 2.1900388613325954 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 340 - cost= 0.61985815 _mse= 2.1922091448913625 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 341 - cost= 0.61985517 _mse= 2.1943803761779974 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 342 - cost= 0.61985195 _mse= 2.19654595618947 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 343 - cost= 0.6198491 _mse= 2.1987209225770945 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 344 - cost= 0.6198456 _mse= 2.200889399658809 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 345 - cost= 0.61984235 _mse= 2.203063153450686 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 346 - cost= 0.6198392 _mse= 2.205231570696353 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 347 - cost= 0.61983573 _mse= 2.2074075852681543 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 348 - cost= 0.61983174 _mse= 2.2095733518894405 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 349 - cost= 0.61982757 _mse= 2.211749073974153 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 350 - cost= 0.6198233 _mse= 2.2139268785989 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 351 - cost= 0.6198179 _mse= 2.215527462438579 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 352 - cost= 0.61981076 _mse= 2.2182271480851123 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 353 - cost= 0.61980015 _mse= 2.220417891424622 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 354 - cost= 0.6197791 _mse= 2.222819788502403 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 355 - cost= 0.61970687 _mse= 2.2248775911508463 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 356 - cost= 0.61883277 _mse= 2.2649788977380014 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 357 - cost= 0.6167967 _mse= 2.3549201175706567 train Accuracy= 0.6694215\n",
      "0.0\n",
      "epoch= 358 - cost= 0.6199642 _mse= 2.2048206185475254 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 359 - cost= 0.6198113 _mse= 2.231813390799661 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 360 - cost= 0.61979824 _mse= 2.2168249264622335 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 361 - cost= 0.6197924 _mse= 2.224279651515403 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 362 - cost= 0.6197895 _mse= 2.224083230023536 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 363 - cost= 0.6197898 _mse= 2.2310717685294845 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 364 - cost= 0.619785 _mse= 2.233641882554669 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 365 - cost= 0.6197812 _mse= 2.2350650975646564 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 366 - cost= 0.61977696 _mse= 2.237456733526961 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 367 - cost= 0.6197722 _mse= 2.239643489843105 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 368 - cost= 0.6197675 _mse= 2.2412858577923336 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 369 - cost= 0.61976284 _mse= 2.244099261051328 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 370 - cost= 0.6197654 _mse= 2.24949204930915 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 371 - cost= 0.6197592 _mse= 2.252616658230377 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 372 - cost= 0.61975294 _mse= 2.253700808902573 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 373 - cost= 0.61974573 _mse= 2.256058714207251 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 374 - cost= 0.61973923 _mse= 2.2389143206536137 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 375 - cost= 0.6196864 _mse= 2.245045019372561 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 376 - cost= 0.61956245 _mse= 2.240753274293898 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 377 - cost= 0.6193271 _mse= 2.2410335393503997 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 378 - cost= 0.61971134 _mse= 2.2425476988876345 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 379 - cost= 0.61960727 _mse= 2.259802347065831 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 380 - cost= 0.61871886 _mse= 2.2479166571549607 train Accuracy= 0.6694215\n",
      "0.0\n",
      "epoch= 381 - cost= 0.6190013 _mse= 2.208668314408037 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 382 - cost= 0.6153155 _mse= 2.300258492482785 train Accuracy= 0.6735537\n",
      "0.0\n",
      "epoch= 383 - cost= 0.66087884 _mse= 2.348825365345722 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 384 - cost= 0.63864595 _mse= 1.975173934283166 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 385 - cost= 0.6246707 _mse= 2.828178230280724 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 386 - cost= 0.6328448 _mse= 2.889293629944956 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 387 - cost= 0.6237915 _mse= 2.461601212722719 train Accuracy= 0.677686\n",
      "0.0\n",
      "epoch= 388 - cost= 0.61329985 _mse= 2.6740687079972765 train Accuracy= 0.6859504\n",
      "0.0\n",
      "epoch= 389 - cost= 0.64262396 _mse= 2.7248221721944637 train Accuracy= 0.6363636\n",
      "0.0\n",
      "epoch= 390 - cost= 0.62230515 _mse= 3.179785510791901 train Accuracy= 0.6818182\n",
      "0.0\n",
      "epoch= 391 - cost= 0.63630027 _mse= 2.3039200659105523 train Accuracy= 0.6652893\n",
      "0.0\n",
      "epoch= 392 - cost= 0.6488339 _mse= 2.1152716160717406 train Accuracy= 0.6487603\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 393 - cost= 0.6337394 _mse= 2.94777539132339 train Accuracy= 0.6818182\n",
      "0.0\n",
      "epoch= 394 - cost= 0.6336327 _mse= 2.1110955834928173 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 395 - cost= 0.6305865 _mse= 2.048391687919014 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 396 - cost= 0.6210136 _mse= 2.424252265910712 train Accuracy= 0.6694215\n",
      "0.0\n",
      "epoch= 397 - cost= 0.6212184 _mse= 2.429978461949211 train Accuracy= 0.6694215\n",
      "0.0\n",
      "epoch= 398 - cost= 0.6168637 _mse= 2.51934525581326 train Accuracy= 0.6694215\n",
      "0.0\n",
      "epoch= 399 - cost= 0.66833174 _mse= 2.3353497342404936 train Accuracy= 0.60330576\n",
      "0.0\n",
      "epoch= 400 - cost= 0.6614055 _mse= 3.0789299464482176 train Accuracy= 0.61157024\n",
      "0.0\n",
      "epoch= 401 - cost= 0.6444377 _mse= 3.020779200968084 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 402 - cost= 0.65300333 _mse= 3.1106741899854833 train Accuracy= 0.61570245\n",
      "0.0\n",
      "epoch= 403 - cost= 0.63528234 _mse= 3.195328632098934 train Accuracy= 0.6446281\n",
      "0.0\n",
      "epoch= 404 - cost= 0.6125168 _mse= 2.795980395755269 train Accuracy= 0.677686\n",
      "0.0\n",
      "epoch= 405 - cost= 0.66919464 _mse= 2.496346673277357 train Accuracy= 0.60330576\n",
      "0.0\n",
      "epoch= 406 - cost= 0.66055226 _mse= 3.4278421913025077 train Accuracy= 0.59917355\n",
      "0.0\n",
      "epoch= 407 - cost= 0.6388313 _mse= 2.9729810473724068 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 408 - cost= 0.6374666 _mse= 2.945514744112037 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 409 - cost= 0.6362568 _mse= 2.9638363687861267 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 410 - cost= 0.63828576 _mse= 2.988209512940977 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 411 - cost= 0.6385592 _mse= 3.0220353292820152 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 412 - cost= 0.63776726 _mse= 3.023230870715364 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 413 - cost= 0.6340361 _mse= 3.146001524172567 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 414 - cost= 0.6381067 _mse= 3.145713330438319 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 415 - cost= 0.6331552 _mse= 3.1516785612148017 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 416 - cost= 0.63686484 _mse= 3.1237910283425507 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 417 - cost= 0.63587546 _mse= 3.189501932002549 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 418 - cost= 0.63896656 _mse= 3.058480901130602 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 419 - cost= 0.6375379 _mse= 3.4793032691939163 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 420 - cost= 0.6369126 _mse= 3.2485595933881783 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 421 - cost= 0.63677734 _mse= 3.2780703292386844 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 422 - cost= 0.6367555 _mse= 3.23214570327738 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 423 - cost= 0.63695246 _mse= 3.2984653733193094 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 424 - cost= 0.63736576 _mse= 3.170446448238018 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 425 - cost= 0.63647896 _mse= 3.5244391549620615 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 426 - cost= 0.63627106 _mse= 3.342301284132925 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 427 - cost= 0.6358989 _mse= 3.5076157533130363 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 428 - cost= 0.6356853 _mse= 3.434262113758125 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 429 - cost= 0.6355407 _mse= 3.470565720484872 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 430 - cost= 0.6354355 _mse= 3.4579520881315142 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 431 - cost= 0.6354389 _mse= 3.4580876948424097 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 432 - cost= 0.6358957 _mse= 3.3003899360227886 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 433 - cost= 0.6356075 _mse= 3.525767216934037 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 434 - cost= 0.6355294 _mse= 3.3994406927745024 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 435 - cost= 0.63576084 _mse= 3.554040660765524 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 436 - cost= 0.6368278 _mse= 3.122171855268286 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 437 - cost= 0.63601726 _mse= 3.4992851597704497 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 438 - cost= 0.6358771 _mse= 3.2938504374193753 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 439 - cost= 0.63546497 _mse= 3.5314326914717538 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 440 - cost= 0.63520294 _mse= 3.396949411621941 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 441 - cost= 0.63504 _mse= 3.463162773313872 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 442 - cost= 0.6350801 _mse= 3.325552772566225 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 443 - cost= 0.6349146 _mse= 3.440111141612973 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 444 - cost= 0.6351343 _mse= 3.285159835174314 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 445 - cost= 0.6348368 _mse= 3.4489684290497302 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 446 - cost= 0.6346809 _mse= 3.378970345277537 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 447 - cost= 0.6346287 _mse= 3.4178330355930067 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 448 - cost= 0.634816 _mse= 3.2903885832936357 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 449 - cost= 0.63455343 _mse= 3.4605886922537876 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 450 - cost= 0.63447654 _mse= 3.368915251951376 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 451 - cost= 0.6344938 _mse= 3.4422474116384314 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 452 - cost= 0.6348997 _mse= 3.2625586515709766 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 453 - cost= 0.63458765 _mse= 3.4983084992389717 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 454 - cost= 0.6343686 _mse= 3.3472436560635463 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 455 - cost= 0.6343412 _mse= 3.4645464919916567 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 456 - cost= 0.63458616 _mse= 3.257099709980544 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 457 - cost= 0.6343659 _mse= 3.4549842858446658 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 458 - cost= 0.63432115 _mse= 3.3521392665744387 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 459 - cost= 0.63418365 _mse= 3.490307829858224 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 460 - cost= 0.63426167 _mse= 3.319643473825014 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 461 - cost= 0.63412833 _mse= 3.450226586073739 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 462 - cost= 0.63403785 _mse= 3.38815448233899 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 463 - cost= 0.6339739 _mse= 3.457499956350654 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 464 - cost= 0.6339562 _mse= 3.4178388953232686 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 465 - cost= 0.63392746 _mse= 3.4696828683489565 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 466 - cost= 0.63400114 _mse= 3.3805536338720406 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 467 - cost= 0.6339267 _mse= 3.499034748995543 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 468 - cost= 0.633985 _mse= 3.3649198942917926 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 469 - cost= 0.63390416 _mse= 3.4795748052733577 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 470 - cost= 0.6338787 _mse= 3.4265878609002427 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 471 - cost= 0.63383776 _mse= 3.5174269361697172 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 472 - cost= 0.63397473 _mse= 3.3811643721873827 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 473 - cost= 0.634132 _mse= 3.5769102894141045 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 474 - cost= 0.6340924 _mse= 3.460974289457388 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 475 - cost= 0.6340788 _mse= 3.64140940751431 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 476 - cost= 0.6345463 _mse= 3.302293275188775 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 477 - cost= 0.6342176 _mse= 3.599840120038167 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 478 - cost= 0.63398814 _mse= 3.398016663773463 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 479 - cost= 0.63385046 _mse= 3.566538120823824 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 480 - cost= 0.63376206 _mse= 3.470349711368647 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 481 - cost= 0.6336989 _mse= 3.565372312571558 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 482 - cost= 0.6336497 _mse= 3.5218050080169 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 483 - cost= 0.6336068 _mse= 3.5787280330251563 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 484 - cost= 0.6335595 _mse= 3.564924789730349 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 485 - cost= 0.6335303 _mse= 3.5538007376977463 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 486 - cost= 0.63356006 _mse= 3.5331690301033714 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 487 - cost= 0.6350645 _mse= 3.6798244805637883 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 488 - cost= 0.6420399 _mse= 2.9421772899097633 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 489 - cost= 0.6540424 _mse= 3.9366436084274885 train Accuracy= 0.62396693\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 490 - cost= 0.6622276 _mse= 3.481241279732822 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 491 - cost= 0.6511072 _mse= 4.159471400370589 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 492 - cost= 0.6404317 _mse= 3.009691771131256 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 493 - cost= 0.63716316 _mse= 3.6613058104541976 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 494 - cost= 0.63621014 _mse= 3.383245718735974 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 495 - cost= 0.6357415 _mse= 3.5985629344954067 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 496 - cost= 0.63463265 _mse= 3.565330349151399 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 497 - cost= 0.6353957 _mse= 3.7156259084519867 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 498 - cost= 0.6344053 _mse= 3.4962788799110096 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 499 - cost= 0.63313 _mse= 3.711881844295627 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 500 - cost= 0.6353341 _mse= 3.6110372342742436 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 501 - cost= 0.63512075 _mse= 3.7663976499509157 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 502 - cost= 0.63523763 _mse= 3.5889506481797464 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 503 - cost= 0.63470334 _mse= 3.783672870512377 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 504 - cost= 0.6315701 _mse= 3.708153790489511 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 505 - cost= 0.62983 _mse= 3.616238643067958 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 506 - cost= 0.63484895 _mse= 3.7258748674946585 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 507 - cost= 0.6349124 _mse= 3.6343744968453753 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 508 - cost= 0.6349451 _mse= 3.7743944334489496 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 509 - cost= 0.6353814 _mse= 3.500598751934351 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 510 - cost= 0.6350655 _mse= 3.7773791283746823 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 511 - cost= 0.63479245 _mse= 3.624145285554404 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 512 - cost= 0.63474554 _mse= 3.8019802341587496 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 513 - cost= 0.63490844 _mse= 3.551090781221388 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 514 - cost= 0.63470626 _mse= 3.731413951536506 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 515 - cost= 0.63452405 _mse= 3.6226491800283385 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 516 - cost= 0.63445723 _mse= 3.722212372793773 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 517 - cost= 0.63462126 _mse= 3.538943675535764 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 518 - cost= 0.63444096 _mse= 3.7199324858469565 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 519 - cost= 0.6342808 _mse= 3.6044790446499753 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 520 - cost= 0.63421845 _mse= 3.6824759890791974 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 521 - cost= 0.6342638 _mse= 3.557674448940122 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 522 - cost= 0.6341302 _mse= 3.6749706064118906 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 523 - cost= 0.63428205 _mse= 3.463376175966992 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 524 - cost= 0.63415337 _mse= 3.584068910393452 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 525 - cost= 0.63405526 _mse= 3.5060571707818635 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 526 - cost= 0.6339748 _mse= 3.569899213183513 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 527 - cost= 0.6339046 _mse= 3.533020703578939 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 528 - cost= 0.6338388 _mse= 3.568500371299444 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 529 - cost= 0.6337621 _mse= 3.559132276450789 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 530 - cost= 0.6337217 _mse= 3.5798916191470265 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 531 - cost= 0.63376105 _mse= 3.4963849922791215 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 532 - cost= 0.63374805 _mse= 3.6033800770245032 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 533 - cost= 0.6339612 _mse= 3.3879044265205605 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 534 - cost= 0.6337893 _mse= 3.5846469733263944 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 535 - cost= 0.63367933 _mse= 3.4493114770046107 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 536 - cost= 0.63359493 _mse= 3.558940703473039 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 537 - cost= 0.6335258 _mse= 3.497296121836735 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 538 - cost= 0.63352704 _mse= 3.5554242000057736 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 539 - cost= 0.63368535 _mse= 3.401936338995201 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 540 - cost= 0.6335534 _mse= 3.570208635860972 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 541 - cost= 0.6334722 _mse= 3.460320081585012 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 542 - cost= 0.6335103 _mse= 3.5562377197015134 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 543 - cost= 0.6338171 _mse= 3.3264802981695776 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 544 - cost= 0.6336284 _mse= 3.5529072552408882 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 545 - cost= 0.63350385 _mse= 3.3975659096040194 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 546 - cost= 0.6334181 _mse= 3.5350670372902107 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 547 - cost= 0.6333556 _mse= 3.4510260043556236 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 548 - cost= 0.6333654 _mse= 3.5317214522557725 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 549 - cost= 0.6335268 _mse= 3.366206793836652 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 550 - cost= 0.6334161 _mse= 3.5358911796213977 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 551 - cost= 0.6333403 _mse= 3.425133584032776 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 552 - cost= 0.633298 _mse= 3.530106636310326 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 553 - cost= 0.63337666 _mse= 3.386197557364901 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 554 - cost= 0.63331497 _mse= 3.4965967044763455 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 555 - cost= 0.6332643 _mse= 3.4256379519185893 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 556 - cost= 0.6332233 _mse= 3.502690742107131 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 557 - cost= 0.63319445 _mse= 3.472672014396013 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 558 - cost= 0.63318765 _mse= 3.5034064266165332 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 559 - cost= 0.63315886 _mse= 3.4823327226861784 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 560 - cost= 0.6331705 _mse= 3.500823949832031 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 561 - cost= 0.6333299 _mse= 3.4012946484945337 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 562 - cost= 0.63359517 _mse= 3.617769291038578 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 563 - cost= 0.6340246 _mse= 3.2436312764930513 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 564 - cost= 0.6337743 _mse= 3.5600643938212624 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 565 - cost= 0.6335729 _mse= 3.3211324927931374 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 566 - cost= 0.63343465 _mse= 3.5355825973610338 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 567 - cost= 0.6333462 _mse= 3.3850552379889978 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 568 - cost= 0.6332797 _mse= 3.525822378329807 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 569 - cost= 0.633229 _mse= 3.422694140575095 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 570 - cost= 0.6331962 _mse= 3.510671097199123 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 571 - cost= 0.6331568 _mse= 3.4596716410735766 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 572 - cost= 0.6331231 _mse= 3.5316922011234793 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 573 - cost= 0.63309634 _mse= 3.5017153504712213 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 574 - cost= 0.63307065 _mse= 3.5451385358915313 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 575 - cost= 0.633048 _mse= 3.5260272893876317 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 576 - cost= 0.6330395 _mse= 3.542603799582765 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 577 - cost= 0.6330885 _mse= 3.545759692994003 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 578 - cost= 0.6351376 _mse= 3.7138674829882334 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 579 - cost= 0.6411272 _mse= 2.827832157084924 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 580 - cost= 0.65260077 _mse= 3.868701961536423 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 581 - cost= 0.64397734 _mse= 2.7991964279937136 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 582 - cost= 0.638942 _mse= 3.5926611953545806 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 583 - cost= 0.63652223 _mse= 3.078282066845293 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 584 - cost= 0.6352692 _mse= 3.4916368335244314 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 585 - cost= 0.6346995 _mse= 3.256036385772074 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 586 - cost= 0.634377 _mse= 3.4674415996625023 train Accuracy= 0.62396693\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 587 - cost= 0.6350959 _mse= 3.586132904818872 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 588 - cost= 0.6364839 _mse= 3.5147476627220353 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 589 - cost= 0.6352831 _mse= 3.1387145822947797 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 590 - cost= 0.6346329 _mse= 3.446088333457279 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 591 - cost= 0.63430417 _mse= 3.269718876593813 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 592 - cost= 0.63412654 _mse= 3.4278009818886637 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 593 - cost= 0.63401985 _mse= 3.348017375651796 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 594 - cost= 0.63395226 _mse= 3.432282567283705 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 595 - cost= 0.63390046 _mse= 3.3976739764800072 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 596 - cost= 0.6338586 _mse= 3.4456303624059097 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 597 - cost= 0.63382393 _mse= 3.4331601131053016 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 598 - cost= 0.6337627 _mse= 3.473756946855718 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 599 - cost= 0.6337103 _mse= 3.4758799292626463 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 600 - cost= 0.63366467 _mse= 3.5169018364921514 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 601 - cost= 0.6336232 _mse= 3.541538590279806 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 602 - cost= 0.6335729 _mse= 3.5834081812031306 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 603 - cost= 0.6335722 _mse= 3.610889635929014 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 604 - cost= 0.6348237 _mse= 3.6486844416007904 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 605 - cost= 0.63851285 _mse= 3.6429978882248544 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 606 - cost= 0.6430684 _mse= 2.473363794461769 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 607 - cost= 0.6386886 _mse= 3.1643470723501212 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 608 - cost= 0.63639474 _mse= 2.673631095217926 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 609 - cost= 0.63522637 _mse= 3.041031101152393 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 610 - cost= 0.63459456 _mse= 2.810288987695022 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 611 - cost= 0.6333777 _mse= 3.0088301207420463 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 612 - cost= 0.6351787 _mse= 3.005405671972607 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 613 - cost= 0.6349641 _mse= 2.9999252490804738 train Accuracy= 0.6487603\n",
      "0.0\n",
      "epoch= 614 - cost= 0.67126554 _mse= 2.5145242496470748 train Accuracy= 0.59504133\n",
      "0.0\n",
      "epoch= 615 - cost= 0.72540396 _mse= 3.3704404887558383 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 616 - cost= 0.69007826 _mse= 5.92966434698917 train Accuracy= 0.44214877\n",
      "0.0\n",
      "epoch= 617 - cost= 0.6637559 _mse= 2.7517026843908896 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 618 - cost= 0.64339435 _mse= 4.31555183716958 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 619 - cost= 0.6280809 _mse= 3.6019027403232697 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 620 - cost= 0.6363998 _mse= 3.9653411598656287 train Accuracy= 0.661157\n",
      "0.0\n",
      "epoch= 621 - cost= 0.6779155 _mse= 2.18514114663639 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 622 - cost= 0.64433056 _mse= 3.8476420421195034 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 623 - cost= 0.63751537 _mse= 2.6601981609160195 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 624 - cost= 0.63203514 _mse= 3.1931404801938004 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 625 - cost= 0.63050437 _mse= 3.0495954726254415 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 626 - cost= 0.633675 _mse= 2.7219601921054624 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 627 - cost= 0.6313759 _mse= 2.9294935077332327 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 628 - cost= 0.6290363 _mse= 3.055366922902738 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 629 - cost= 0.6236996 _mse= 3.0100218650014616 train Accuracy= 0.6528926\n",
      "0.0\n",
      "epoch= 630 - cost= 0.63089687 _mse= 3.0763673368355873 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 631 - cost= 0.6522561 _mse= 2.0740409224003766 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 632 - cost= 0.637606 _mse= 3.1826269583614737 train Accuracy= 0.6446281\n",
      "0.0\n",
      "epoch= 633 - cost= 0.628645 _mse= 2.5353668596005163 train Accuracy= 0.6446281\n",
      "0.0\n",
      "epoch= 634 - cost= 0.62731516 _mse= 2.7044895195460046 train Accuracy= 0.6446281\n",
      "0.0\n",
      "epoch= 635 - cost= 0.62155473 _mse= 2.626831135501638 train Accuracy= 0.6570248\n",
      "0.0\n",
      "epoch= 636 - cost= 0.6244735 _mse= 2.8094065016309044 train Accuracy= 0.6528926\n",
      "0.0\n",
      "epoch= 637 - cost= 0.6556204 _mse= 1.8782881606357753 train Accuracy= 0.6198347\n",
      "0.0\n",
      "epoch= 638 - cost= 0.6347715 _mse= 2.9820441811930505 train Accuracy= 0.6446281\n",
      "0.0\n",
      "epoch= 639 - cost= 0.62888205 _mse= 2.239806042371666 train Accuracy= 0.6487603\n",
      "0.0\n",
      "epoch= 640 - cost= 0.6263945 _mse= 2.429748643838305 train Accuracy= 0.6446281\n",
      "0.0\n",
      "epoch= 641 - cost= 0.6333901 _mse= 2.222443063741452 train Accuracy= 0.6404959\n",
      "0.0\n",
      "epoch= 642 - cost= 0.63178784 _mse= 2.4905258497172422 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 643 - cost= 0.6306356 _mse= 2.4822746021396283 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 644 - cost= 0.63066995 _mse= 2.4477261477912102 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 645 - cost= 0.6296954 _mse= 2.507632603128328 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 646 - cost= 0.6346955 _mse= 2.203762504738896 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 647 - cost= 0.6325377 _mse= 2.460745150512247 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 648 - cost= 0.6311344 _mse= 2.4019449995822617 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 649 - cost= 0.6308371 _mse= 2.453788246975644 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 650 - cost= 0.6309805 _mse= 2.334622969949999 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 651 - cost= 0.6305073 _mse= 2.4527659477277943 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 652 - cost= 0.63059455 _mse= 2.338911090888741 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 653 - cost= 0.6302359 _mse= 2.4252298056730237 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 654 - cost= 0.6299847 _mse= 2.414218379223011 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 655 - cost= 0.62993515 _mse= 2.3658932041495757 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 656 - cost= 0.6298938 _mse= 2.437220952237841 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 657 - cost= 0.63047457 _mse= 2.2500148530668986 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 658 - cost= 0.6296476 _mse= 2.4298894555093082 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 659 - cost= 0.6293828 _mse= 2.3866536153745885 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 660 - cost= 0.6292468 _mse= 2.4219416182117177 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 661 - cost= 0.62924105 _mse= 2.370899891069426 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 662 - cost= 0.62908405 _mse= 2.4316750791213932 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 663 - cost= 0.629109 _mse= 2.3708876098295946 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 664 - cost= 0.6289792 _mse= 2.4322694909635714 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 665 - cost= 0.6289119 _mse= 2.429180661159341 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 666 - cost= 0.62892413 _mse= 2.4038626089717514 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 667 - cost= 0.62904644 _mse= 2.4394965162982625 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 668 - cost= 0.62985384 _mse= 2.2769894500209276 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 669 - cost= 0.6290677 _mse= 2.462684800809187 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 670 - cost= 0.6288795 _mse= 2.409134118390079 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 671 - cost= 0.62879026 _mse= 2.449682004986383 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 672 - cost= 0.6287306 _mse= 2.4539206927842336 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 673 - cost= 0.62871915 _mse= 2.468372397410868 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 674 - cost= 0.6288182 _mse= 2.4141250801325893 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 675 - cost= 0.62865955 _mse= 2.501747914026647 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 676 - cost= 0.6286764 _mse= 2.5197669715620745 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 677 - cost= 0.6315975 _mse= 2.5075405005355003 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 678 - cost= 0.644256 _mse= 2.8476932962721286 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 679 - cost= 0.66209644 _mse= 1.618120681747938 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 680 - cost= 0.6362662 _mse= 2.372356004760134 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 681 - cost= 0.6317672 _mse= 2.0086463130035446 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 682 - cost= 0.6311058 _mse= 2.1148393075161156 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 683 - cost= 0.6308042 _mse= 2.1062544182968117 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 684 - cost= 0.6305696 _mse= 2.1333205298675626 train Accuracy= 0.6280992\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 685 - cost= 0.6303691 _mse= 2.1471223011159632 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 686 - cost= 0.6301989 _mse= 2.16476918451169 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 687 - cost= 0.63004726 _mse= 2.182774236597052 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 688 - cost= 0.629907 _mse= 2.2012672471429173 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 689 - cost= 0.62975824 _mse= 2.216289979054446 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 690 - cost= 0.6296309 _mse= 2.2326392516603595 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 691 - cost= 0.6295087 _mse= 2.2497686077157435 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 692 - cost= 0.6293788 _mse= 2.265759749344562 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 693 - cost= 0.6291784 _mse= 2.2821537900588944 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 694 - cost= 0.62586427 _mse= 2.297847330229874 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 695 - cost= 0.62579596 _mse= 2.295547928101908 train Accuracy= 0.6322314\n",
      "0.0\n",
      "epoch= 696 - cost= 0.64423394 _mse= 2.30735079793383 train Accuracy= 0.6280992\n",
      "0.0\n",
      "epoch= 697 - cost= 0.6339808 _mse= 1.8151989681738507 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 698 - cost= 0.6331003 _mse= 1.9805739930674282 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 699 - cost= 0.6329243 _mse= 1.9376038605757258 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 700 - cost= 0.632843 _mse= 1.9696480327222812 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 701 - cost= 0.63278973 _mse= 1.9751412434095295 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 702 - cost= 0.63276905 _mse= 1.9777128311014376 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 703 - cost= 0.6327181 _mse= 1.9886883172312908 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 704 - cost= 0.6326663 _mse= 2.001544746274559 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 705 - cost= 0.632757 _mse= 2.031257390174564 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 706 - cost= 0.6330284 _mse= 2.1097132114235455 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 707 - cost= 0.6326578 _mse= 2.0062770093692595 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 708 - cost= 0.6325777 _mse= 2.0562117168635985 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 709 - cost= 0.6325376 _mse= 2.0501350784414787 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 710 - cost= 0.6325047 _mse= 2.0647085805336087 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 711 - cost= 0.63247395 _mse= 2.0717871642512358 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 712 - cost= 0.6324557 _mse= 2.0843864800494574 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 713 - cost= 0.63245785 _mse= 2.105003762915997 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 714 - cost= 0.6324186 _mse= 2.0938086016374013 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 715 - cost= 0.6323896 _mse= 2.109917280950824 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 716 - cost= 0.63237876 _mse= 2.119201123273628 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 717 - cost= 0.63237417 _mse= 2.1398435445360957 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 718 - cost= 0.6323384 _mse= 2.1251800098792057 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 719 - cost= 0.6323534 _mse= 2.1493743917775356 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 720 - cost= 0.63232064 _mse= 2.1426929641099712 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 721 - cost= 0.6322958 _mse= 2.1570542327999944 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 722 - cost= 0.6322729 _mse= 2.1638711228364587 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 723 - cost= 0.63226074 _mse= 2.1782752419631604 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 724 - cost= 0.63227314 _mse= 2.195892949560327 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 725 - cost= 0.63224447 _mse= 2.1846293979672398 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 726 - cost= 0.63222384 _mse= 2.204645285739291 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 727 - cost= 0.6322112 _mse= 2.2070332711433083 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 728 - cost= 0.63227606 _mse= 2.2379598150247024 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 729 - cost= 0.63222677 _mse= 2.2071484907664956 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 730 - cost= 0.63218987 _mse= 2.240878254005606 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 731 - cost= 0.6321654 _mse= 2.234380056729346 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 732 - cost= 0.63215005 _mse= 2.250223731634509 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 733 - cost= 0.63213253 _mse= 2.2520098708933185 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 734 - cost= 0.6321292 _mse= 2.272411572176596 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 735 - cost= 0.6321442 _mse= 2.299134333081299 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 736 - cost= 0.6320936 _mse= 2.2758032591193227 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 737 - cost= 0.63205713 _mse= 2.3102990058353394 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 738 - cost= 0.63206005 _mse= 2.3125073651220243 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 739 - cost= 0.6322151 _mse= 2.367284978213136 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 740 - cost= 0.63209444 _mse= 2.304563951325277 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 741 - cost= 0.632021 _mse= 2.3688509347917237 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 742 - cost= 0.6319745 _mse= 2.340300182813874 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 743 - cost= 0.63193214 _mse= 2.3815855476179633 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 744 - cost= 0.63192034 _mse= 2.3729607168953692 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 745 - cost= 0.6319404 _mse= 2.4126680796042788 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 746 - cost= 0.63189584 _mse= 2.3830148273287395 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 747 - cost= 0.63185626 _mse= 2.4242922811628853 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 748 - cost= 0.6318292 _mse= 2.4116129683501812 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 749 - cost= 0.63181293 _mse= 2.4410044467227463 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 750 - cost= 0.63216263 _mse= 2.451546114474039 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 751 - cost= 0.6350357 _mse= 2.5677883883220236 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 752 - cost= 0.63820565 _mse= 1.9031228746316637 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 753 - cost= 0.63429743 _mse= 2.2888125504418575 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 754 - cost= 0.63269776 _mse= 2.024312440359426 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 755 - cost= 0.63234776 _mse= 2.1449068820266453 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 756 - cost= 0.6322456 _mse= 2.100557525011814 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 757 - cost= 0.6322104 _mse= 2.1323012277418347 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 758 - cost= 0.6321861 _mse= 2.129290310703383 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 759 - cost= 0.63216513 _mse= 2.1417846368892905 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 760 - cost= 0.6321454 _mse= 2.1470805425098276 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 761 - cost= 0.63212645 _mse= 2.15549562928575 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 762 - cost= 0.6321081 _mse= 2.1623484886596813 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 763 - cost= 0.6320905 _mse= 2.1697855510543325 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 764 - cost= 0.6320734 _mse= 2.176807057704992 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 765 - cost= 0.6320606 _mse= 2.1859147561834487 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 766 - cost= 0.63206387 _mse= 2.1999756895840887 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 767 - cost= 0.6320448 _mse= 2.194749200825951 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 768 - cost= 0.63203466 _mse= 2.2095689443837534 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 769 - cost= 0.63201773 _mse= 2.2107231588610428 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 770 - cost= 0.6320019 _mse= 2.2199694165659363 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 771 - cost= 0.6319935 _mse= 2.2267291215342775 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 772 - cost= 0.6319896 _mse= 2.2354781324930992 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 773 - cost= 0.63200814 _mse= 2.2556879892152457 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 774 - cost= 0.6319791 _mse= 2.238415488861934 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 775 - cost= 0.63196105 _mse= 2.256074542438679 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 776 - cost= 0.63194996 _mse= 2.258755424988753 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 777 - cost= 0.63193727 _mse= 2.2718286304362074 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 778 - cost= 0.6319241 _mse= 2.2711924016923533 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 779 - cost= 0.6319178 _mse= 2.2793929088175755 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 780 - cost= 0.6319136 _mse= 2.2866244987062236 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 781 - cost= 0.6319331 _mse= 2.3065054757678074 train Accuracy= 0.62396693\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 782 - cost= 0.63190687 _mse= 2.2891374721634716 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 783 - cost= 0.6318901 _mse= 2.3066384161797493 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 784 - cost= 0.63188267 _mse= 2.306815812627819 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 785 - cost= 0.63186413 _mse= 2.3219176466822855 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 786 - cost= 0.63184464 _mse= 2.336600020975452 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 787 - cost= 0.6318249 _mse= 2.344645231144541 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 788 - cost= 0.63183093 _mse= 2.3658028036176706 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 789 - cost= 0.63180375 _mse= 2.357533941698907 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 790 - cost= 0.6317785 _mse= 2.3852511433777948 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 791 - cost= 0.63176155 _mse= 2.3839442424999424 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 792 - cost= 0.6317453 _mse= 2.409818381515077 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 793 - cost= 0.6317387 _mse= 2.4006496522865133 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 794 - cost= 0.63175094 _mse= 2.4361753015667746 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 795 - cost= 0.631721 _mse= 2.412574176704561 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 796 - cost= 0.631699 _mse= 2.448449115991651 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 797 - cost= 0.6316917 _mse= 2.4428829823613896 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 798 - cost= 0.631703 _mse= 2.483162421342293 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 799 - cost= 0.63171244 _mse= 2.452800979385065 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 800 - cost= 0.63187194 _mse= 2.5155395957580122 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 801 - cost= 0.63178957 _mse= 2.4440363383282087 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 802 - cost= 0.63172215 _mse= 2.5185927837090136 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 803 - cost= 0.631676 _mse= 2.468875243475009 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 804 - cost= 0.6316961 _mse= 2.5259775273954723 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 805 - cost= 0.6319569 _mse= 2.400527943408829 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 806 - cost= 0.6319919 _mse= 2.521037991889601 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 807 - cost= 0.63188994 _mse= 2.414730189879779 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 808 - cost= 0.63180476 _mse= 2.5210611862174495 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 809 - cost= 0.63178533 _mse= 2.4510794438220564 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 810 - cost= 0.6320855 _mse= 2.552157681536882 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 811 - cost= 0.63196087 _mse= 2.4454791149093698 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 812 - cost= 0.63194543 _mse= 2.5477686621276256 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 813 - cost= 0.6323429 _mse= 2.322149662897802 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 814 - cost= 0.63213503 _mse= 2.4747564040066585 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 815 - cost= 0.6318191 _mse= 2.341947023191904 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 816 - cost= 0.6316995 _mse= 2.4290437830433507 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 817 - cost= 0.63167304 _mse= 2.4046950440454604 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 818 - cost= 0.6316544 _mse= 2.444061498501436 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 819 - cost= 0.6316307 _mse= 2.427148501734508 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 820 - cost= 0.63160944 _mse= 2.4647790690728675 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 821 - cost= 0.63159066 _mse= 2.4530126379565154 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 822 - cost= 0.631573 _mse= 2.484226057875727 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 823 - cost= 0.63155615 _mse= 2.4768432314773947 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 824 - cost= 0.63154733 _mse= 2.504879143505407 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 825 - cost= 0.6315327 _mse= 2.4975710534051423 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 826 - cost= 0.63151884 _mse= 2.52241126561659 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 827 - cost= 0.6315572 _mse= 2.501523844096063 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 828 - cost= 0.6316596 _mse= 2.5497286159587733 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 829 - cost= 0.6317727 _mse= 2.406129350378362 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 830 - cost= 0.6317185 _mse= 2.4994426493976434 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 831 - cost= 0.6316746 _mse= 2.436955980860533 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 832 - cost= 0.63163674 _mse= 2.5140339198283668 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 833 - cost= 0.631621 _mse= 2.4666318519860138 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 834 - cost= 0.6316293 _mse= 2.5369671074125 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 835 - cost= 0.63159853 _mse= 2.4828634247090213 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 836 - cost= 0.6315742 _mse= 2.543648128486828 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 837 - cost= 0.63155955 _mse= 2.503161556052085 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 838 - cost= 0.6319103 _mse= 2.5723582343384117 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 839 - cost= 0.6324561 _mse= 2.3303019273135797 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 840 - cost= 0.63213533 _mse= 2.5098583360130804 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 841 - cost= 0.6317881 _mse= 2.362426245313462 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 842 - cost= 0.63165146 _mse= 2.460288123622592 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 843 - cost= 0.63158983 _mse= 2.414176814519692 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 844 - cost= 0.631561 _mse= 2.455217375711206 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 845 - cost= 0.6315414 _mse= 2.444008067740349 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 846 - cost= 0.63152224 _mse= 2.4666986154185317 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 847 - cost= 0.63150835 _mse= 2.476647117545154 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 848 - cost= 0.63149476 _mse= 2.4872794915572825 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 849 - cost= 0.63148177 _mse= 2.4970228605574865 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 850 - cost= 0.6314704 _mse= 2.508167697593392 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 851 - cost= 0.63146037 _mse= 2.519900391720925 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 852 - cost= 0.6314481 _mse= 2.524232646242558 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 853 - cost= 0.63143677 _mse= 2.536666061214289 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 854 - cost= 0.63143593 _mse= 2.544341031817507 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 855 - cost= 0.6314991 _mse= 2.5555820241872964 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 856 - cost= 0.63225776 _mse= 2.4592005492376274 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 857 - cost= 0.6339021 _mse= 2.649898139591032 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 858 - cost= 0.6326624 _mse= 2.39739028905824 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 859 - cost= 0.63217336 _mse= 2.599363652421391 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 860 - cost= 0.632577 _mse= 2.2973659479231796 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 861 - cost= 0.632036 _mse= 2.4954228337337394 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 862 - cost= 0.6318197 _mse= 2.3833144456307784 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 863 - cost= 0.6317145 _mse= 2.4632806463126284 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 864 - cost= 0.6316596 _mse= 2.4218756388688965 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 865 - cost= 0.63162154 _mse= 2.4597668804393384 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 866 - cost= 0.63159555 _mse= 2.4524322207578377 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 867 - cost= 0.63157034 _mse= 2.467070027653903 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 868 - cost= 0.63154626 _mse= 2.469404219884681 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 869 - cost= 0.6315248 _mse= 2.482376751182898 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 870 - cost= 0.63150585 _mse= 2.4874167908964946 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 871 - cost= 0.6314884 _mse= 2.492551350832132 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 872 - cost= 0.6314695 _mse= 2.4997262744263606 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 873 - cost= 0.63145185 _mse= 2.50968950585919 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 874 - cost= 0.63143635 _mse= 2.5184649685066516 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 875 - cost= 0.6314248 _mse= 2.529263066498026 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 876 - cost= 0.6314133 _mse= 2.5365572267321066 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 877 - cost= 0.6314024 _mse= 2.5474066913364513 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 878 - cost= 0.63139665 _mse= 2.553934958755757 train Accuracy= 0.62396693\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 879 - cost= 0.6313988 _mse= 2.54354893385168 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 880 - cost= 0.63138765 _mse= 2.5557677645658337 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 881 - cost= 0.6313826 _mse= 2.5610141622888194 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 882 - cost= 0.63137907 _mse= 2.5562637797199326 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 883 - cost= 0.63146055 _mse= 2.5766031018682476 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 884 - cost= 0.6321479 _mse= 2.4572633453866204 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 885 - cost= 0.63289684 _mse= 2.6726432683890855 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 886 - cost= 0.632139 _mse= 2.4291116317903536 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 887 - cost= 0.6317906 _mse= 2.5842445301617376 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 888 - cost= 0.63162977 _mse= 2.484523728244472 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 889 - cost= 0.63154817 _mse= 2.557976355809922 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 890 - cost= 0.6314998 _mse= 2.519294411799758 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 891 - cost= 0.63146883 _mse= 2.554714418351626 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 892 - cost= 0.63144916 _mse= 2.5407495646050196 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 893 - cost= 0.6314394 _mse= 2.5389111552093713 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 894 - cost= 0.63142157 _mse= 2.551192956153716 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 895 - cost= 0.6314128 _mse= 2.550387998959487 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 896 - cost= 0.63140756 _mse= 2.539473066125172 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 897 - cost= 0.6314252 _mse= 2.5656617850052874 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 898 - cost= 0.63154554 _mse= 2.4819507086775117 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 899 - cost= 0.6314525 _mse= 2.5739001372342165 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 900 - cost= 0.6314042 _mse= 2.5242430798791236 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 901 - cost= 0.63137525 _mse= 2.5685008591357152 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 902 - cost= 0.6313551 _mse= 2.550440268389272 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 903 - cost= 0.6313589 _mse= 2.571053571800433 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 904 - cost= 0.6314198 _mse= 2.5180986271732615 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 905 - cost= 0.6313975 _mse= 2.5803684491492533 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 906 - cost= 0.63135993 _mse= 2.5403295244998274 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 907 - cost= 0.6313474 _mse= 2.576648156481534 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 908 - cost= 0.6313723 _mse= 2.527301661104138 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 909 - cost= 0.6313469 _mse= 2.5736382429146065 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 910 - cost= 0.6313302 _mse= 2.5540111845683384 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 911 - cost= 0.63132507 _mse= 2.5781516425858158 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 912 - cost= 0.63133407 _mse= 2.5484156921132795 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 913 - cost= 0.6313181 _mse= 2.5815133930853977 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 914 - cost= 0.6313093 _mse= 2.5700701436723348 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 915 - cost= 0.6313606 _mse= 2.5853390913401277 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 916 - cost= 0.6316356 _mse= 2.47510853748277 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 917 - cost= 0.63147336 _mse= 2.6095513331885627 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 918 - cost= 0.6313844 _mse= 2.5263250795650745 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 919 - cost= 0.63133854 _mse= 2.5934968503101894 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 920 - cost= 0.63131267 _mse= 2.5586501297138406 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 921 - cost= 0.6312959 _mse= 2.5935891391650183 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 922 - cost= 0.631288 _mse= 2.5807985210224076 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 923 - cost= 0.6313448 _mse= 2.5967976728666415 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 924 - cost= 0.6318905 _mse= 2.49335997956136 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 925 - cost= 0.6326747 _mse= 2.712674581638567 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 926 - cost= 0.63327235 _mse= 2.277520469631326 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 927 - cost= 0.6323842 _mse= 2.5588850377847314 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 928 - cost= 0.63194525 _mse= 2.3691444861480533 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 929 - cost= 0.6317278 _mse= 2.507302901337521 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 930 - cost= 0.63162136 _mse= 2.4239952320704385 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 931 - cost= 0.63155836 _mse= 2.4884952882266833 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 932 - cost= 0.6315172 _mse= 2.4547092111238773 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 933 - cost= 0.63148844 _mse= 2.4909331244038393 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 934 - cost= 0.63146544 _mse= 2.4791652055025435 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 935 - cost= 0.63144636 _mse= 2.4994076777534686 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 936 - cost= 0.63142866 _mse= 2.497674543008615 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 937 - cost= 0.631412 _mse= 2.5103175182496633 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 938 - cost= 0.631396 _mse= 2.5132322230507125 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 939 - cost= 0.6313815 _mse= 2.5222406684854786 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 940 - cost= 0.6313668 _mse= 2.5272830146214176 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 941 - cost= 0.63135296 _mse= 2.5345119917400356 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 942 - cost= 0.6313409 _mse= 2.5404837858136236 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 943 - cost= 0.631331 _mse= 2.5479378049806973 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 944 - cost= 0.63132143 _mse= 2.5543281376658866 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 945 - cost= 0.6313131 _mse= 2.559890793328377 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 946 - cost= 0.6313048 _mse= 2.5666895607394835 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 947 - cost= 0.63129634 _mse= 2.5736719820000578 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 948 - cost= 0.6312877 _mse= 2.582231872797851 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 949 - cost= 0.6312793 _mse= 2.589572331060276 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 950 - cost= 0.6312718 _mse= 2.5974267154387043 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 951 - cost= 0.63126355 _mse= 2.605193081627384 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 952 - cost= 0.63125575 _mse= 2.6118052227791635 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 953 - cost= 0.6312486 _mse= 2.619803720789483 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 954 - cost= 0.63124096 _mse= 2.626387191387608 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 955 - cost= 0.6312335 _mse= 2.6349379982213836 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 956 - cost= 0.63122666 _mse= 2.640674584113555 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 957 - cost= 0.63122684 _mse= 2.651024675859315 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 958 - cost= 0.63131046 _mse= 2.6644891579098826 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 959 - cost= 0.631708 _mse= 2.5363055645764097 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 960 - cost= 0.63165736 _mse= 2.6809204276117984 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 961 - cost= 0.6314592 _mse= 2.5365361613703152 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 962 - cost= 0.6313511 _mse= 2.64886365844161 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 963 - cost= 0.63129216 _mse= 2.577281558753459 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 964 - cost= 0.63125753 _mse= 2.6392239678634835 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 965 - cost= 0.63123655 _mse= 2.60482734572559 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 966 - cost= 0.63129944 _mse= 2.653518576893175 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 967 - cost= 0.6312626 _mse= 2.618609670022075 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 968 - cost= 0.6312393 _mse= 2.6519725373677745 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 969 - cost= 0.631243 _mse= 2.6139631950746405 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 970 - cost= 0.6312246 _mse= 2.6463846387455567 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 971 - cost= 0.6312116 _mse= 2.631332022142591 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 972 - cost= 0.6312041 _mse= 2.650401594299184 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 973 - cost= 0.6312139 _mse= 2.6239448742359586 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 974 - cost= 0.631204 _mse= 2.649217251946547 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 975 - cost= 0.63119537 _mse= 2.641320409784501 train Accuracy= 0.62396693\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 976 - cost= 0.63119584 _mse= 2.6550331360464616 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 977 - cost= 0.63120276 _mse= 2.631671289178371 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 978 - cost= 0.63119555 _mse= 2.6631751660994913 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 979 - cost= 0.6312086 _mse= 2.625198101112422 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 980 - cost= 0.63119566 _mse= 2.6597216130091925 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 981 - cost= 0.6311877 _mse= 2.645292695656213 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 982 - cost= 0.6311985 _mse= 2.6679439932286115 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 983 - cost= 0.6312439 _mse= 2.6143925998172324 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 984 - cost= 0.63122 _mse= 2.6694917256578394 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 985 - cost= 0.63119894 _mse= 2.632876585239917 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 986 - cost= 0.6311851 _mse= 2.6703717285589645 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 987 - cost= 0.6311889 _mse= 2.6553597370273465 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 988 - cost= 0.6312802 _mse= 2.6898544558160977 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 989 - cost= 0.63153046 _mse= 2.542009151696629 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 990 - cost= 0.6313841 _mse= 2.679966170533293 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 991 - cost= 0.6313004 _mse= 2.585015111703476 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 992 - cost= 0.6312169 _mse= 2.6715239171276095 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 993 - cost= 0.6313026 _mse= 2.6570396035891144 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 994 - cost= 0.6317127 _mse= 2.74379912220055 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 995 - cost= 0.63149196 _mse= 2.580686591771069 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 996 - cost= 0.6313616 _mse= 2.704007728439507 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 997 - cost= 0.6312879 _mse= 2.6186087105668334 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 998 - cost= 0.6312413 _mse= 2.687375386809348 train Accuracy= 0.62396693\n",
      "0.0\n",
      "epoch= 999 - cost= 0.63120836 _mse= 2.6414847510402346 train Accuracy= 0.62396693\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "mse_history=[]\n",
    "accuracy_history=[]\n",
    "batch_size=1\n",
    "tf.convert_to_tensor(xtest)\n",
    "\n",
    "#training the model\n",
    "for epoch in range (training_epoch):\n",
    "\n",
    "    sess.run(training_step,feed_dict={x:xtrain,y_:ytrain})\n",
    "    cost=sess.run(cost_function,feed_dict={x:xtrain,y_:ytrain})\n",
    "    cost_history=np.append(cost_history,cost)\n",
    "    correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    ypred=sess.run(y,feed_dict={x:xtest})\n",
    "    '''tf.convert_to_tensor(ypred)'''\n",
    "    tf.convert_to_tensor(ypred)\n",
    "    mse=tf.reduce_mean(tf.square(ypred - ytest))\n",
    "    mse_=sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy=(sess.run(accuracy,feed_dict={x:xtrain,y_:ytrain}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    print('epoch=',epoch,'-','cost=',cost,'_mse=',mse_,\"train Accuracy=\",accuracy)\n",
    "    print((ypred==ytest).sum()/len(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c87b1c8>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot accuracy and mse\n",
    "plt.plot(mse_history,'r')\n",
    "plt.show()\n",
    "plt.plot(accuracy_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy= 0.47540984\n"
     ]
    }
   ],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print(\"Test accuracy=\",(sess.run(accuracy,feed_dict={x:xtest,y_:ytest})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
